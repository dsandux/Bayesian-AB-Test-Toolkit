{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "### Hi! My name is Lucas Pereira, and I'm the creator of this notebook. It's great to have you here!\n",
    "\n",
    "You can find the original project on my GitHub and connect with me on LinkedIn.\n",
    "\n",
    "* **Original notebook:** [https://github.com/dsandux/AB-Test-Toolkit](https://github.com/dsandux/AB-Test-Toolkit)\n",
    "* **LinkedIn:** [https://www.linkedin.com/in/lucaspereira](https://www.linkedin.com/in/lucaspereira)\n",
    "---"
   ],
   "id": "fa75c0ae6c4ba362"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# A/B Test Analysis with Bayesian Statistics\n",
    "This notebook performs an end-to-end analysis of A/B test results using Bayesian statistical methods. The objective is to go beyond the traditional \"p-value\" to calculate the probability of each variant being the best and to quantify the expected risk associated with choosing one variant over another."
   ],
   "id": "abf4300b80bcbe16"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### 1. Setup\n",
    "\n",
    "Here is where we install all the libraries needed to run this test.\n"
   ],
   "id": "93851f08a4e7811b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 1. Setup: Load Libraries\n",
    "# This cell installs and imports all the necessary Python libraries for the analysis,\n",
    "# visualization, and interactive controls.\n",
    "# You only need to run this cell once per session.\n",
    "\n",
    "# --- Install required packages ---\n",
    "!pip install -q pandas numpy scipy matplotlib seaborn ipywidgets\n",
    "\n",
    "# --- Import Libraries ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.ticker import PercentFormatter, FuncFormatter\n",
    "import os\n",
    "\n",
    "# --- New libraries for interactive widgets and file handling ---\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "import io\n",
    "\n",
    "print(\"‚úÖ Libraries loaded successfully. You can now proceed to the Control Panel.\")\n"
   ],
   "id": "a427fe66ce8fc60d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### 2. Upload files and set parameters\n",
    "\n",
    "Run the cell below to see the upload file and settings form. The default settings are better for most of cases (unless you have a specific need and knows what the options means). You can just upload your Excel file and run the cell."
   ],
   "id": "7a627bb742ef4064"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# --- 2. Control Panel ---\n",
    "# Use the controls below to configure your test. After making your selections,\n",
    "# click the \"Confirm Selections\" button to prepare the data for analysis.\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "from datetime import datetime\n",
    "import os\n",
    "import io\n",
    "\n",
    "# --- Define Layouts for a cleaner and more professional look ---\n",
    "# This helps align widgets and give them consistent sizing and spacing.\n",
    "wide_layout = widgets.Layout(width='98%', margin='5px 0')\n",
    "button_layout = widgets.Layout(width='250px', margin='15px 0 0 0')\n",
    "\n",
    "# --- Create Interactive Widgets ---\n",
    "\n",
    "# File Uploader Widget\n",
    "uploader = widgets.FileUpload(\n",
    "    accept='.xlsx',\n",
    "    description='Upload Data File',\n",
    "    button_style='info',\n",
    "    tooltip='Click to upload your A/B test data in .xlsx format',\n",
    "    layout=wide_layout\n",
    ")\n",
    "\n",
    "# Bayesian Prior Selector Widget\n",
    "prior_selector = widgets.Dropdown(\n",
    "    options=[\n",
    "        ('Jeffreys (Recommended for most tests)', (0.5, 0.5)),\n",
    "        ('Uniform (Neutral / Uninformative)', (1.0, 1.0))\n",
    "    ],\n",
    "    value=(0.5, 0.5),\n",
    "    description='Bayesian Prior:',\n",
    "    style={'description_width': 'initial'},\n",
    "    tooltip='Choose the starting assumption for the model.',\n",
    "    layout=wide_layout\n",
    ")\n",
    "\n",
    "# Risk Threshold Slider Widget\n",
    "risk_slider = widgets.FloatSlider(\n",
    "    value=0.01,\n",
    "    min=0.005,\n",
    "    max=0.05,\n",
    "    step=0.005,\n",
    "    description='Risk Tolerance:',\n",
    "    style={'description_width': 'initial'},\n",
    "    readout_format='.2%',\n",
    "    tooltip='Lower = more cautious. Higher = more aggressive.',\n",
    "    layout=wide_layout\n",
    ")\n",
    "\n",
    "# --- Add Button and Output Area for Feedback ---\n",
    "\n",
    "# Button to confirm the upload and parameter settings\n",
    "confirm_button = widgets.Button(\n",
    "    description=\"Confirm Selections\",\n",
    "    button_style='success',\n",
    "    tooltip='Click to confirm your file and settings',\n",
    "    icon='check',\n",
    "    layout=button_layout\n",
    ")\n",
    "\n",
    "# Output widget to display feedback messages (success or error)\n",
    "output_area = widgets.Output()\n",
    "\n",
    "# --- Define the logic for the button click ---\n",
    "def on_confirm_button_clicked(b):\n",
    "    with output_area:\n",
    "        clear_output(wait=True) # Clear previous messages\n",
    "\n",
    "        # Add a try-except block for robust error handling\n",
    "        try:\n",
    "            # Check if a file has been uploaded\n",
    "            if not uploader.value:\n",
    "                print(\"‚ùå Error: Please upload a data file before confirming.\")\n",
    "                return\n",
    "\n",
    "            # Access the uploaded file's data and name\n",
    "            uploaded_file_dict = uploader.value[0]\n",
    "            original_name = uploaded_file_dict['name']\n",
    "\n",
    "            # Create the new filename with the current date\n",
    "            date_str = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "            base_name, extension = os.path.splitext(original_name)\n",
    "            new_filename_with_date = f\"{base_name}_{date_str}{extension}\"\n",
    "\n",
    "            # Store the data and new filename in global variables\n",
    "            global uploaded_data_content, confirmed_filename\n",
    "            uploaded_data_content = io.BytesIO(uploaded_file_dict['content'])\n",
    "            confirmed_filename = new_filename_with_date\n",
    "\n",
    "            # Provide success feedback to the user\n",
    "            print(f\"‚úÖ Success! File '{original_name}' is ready for analysis.\")\n",
    "            print(f\"   It will be referred to as '{confirmed_filename}' in this session.\")\n",
    "            print(\"\\nYou may now proceed to the next cell.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            # If any error occurs, print it clearly for debugging.\n",
    "            print(\"‚ùå An unexpected error occurred. Please check the details below:\")\n",
    "            print(f\"   Error Type: {type(e).__name__}\")\n",
    "            print(f\"   Error Details: {e}\")\n",
    "\n",
    "\n",
    "# Link the function to the button's click event\n",
    "confirm_button.on_click(on_confirm_button_clicked)\n",
    "\n",
    "# --- Display the final Control Panel using a VBox and Accordion for a structured layout ---\n",
    "# We use an Accordion to tuck away the more advanced settings, simplifying the UI.\n",
    "advanced_settings = widgets.Accordion(\n",
    "    children=[widgets.VBox([prior_selector, risk_slider])],\n",
    "    selected_index=None # Start with the accordion closed\n",
    ")\n",
    "advanced_settings.set_title(0, 'Advanced Settings (Prior & Risk)')\n",
    "advanced_settings.layout = wide_layout\n",
    "\n",
    "\n",
    "# The main VBox organizes all the elements vertically and adds a border.\n",
    "control_panel_layout = widgets.VBox([\n",
    "    widgets.HTML(\"<h2 style='font-family: Arial, sans-serif;'>Step 1: Configure Your Test</h2>\"),\n",
    "    widgets.HTML(\"<b style='font-family: Arial, sans-serif;'>Upload your data file and adjust the settings below, then click Confirm.</b>\"),\n",
    "    uploader,\n",
    "    advanced_settings,\n",
    "    confirm_button,\n",
    "    output_area\n",
    "], layout=widgets.Layout(\n",
    "    border='1px solid #ccc',\n",
    "    padding='15px',\n",
    "    border_radius='8px',\n",
    "    margin='10px 0'\n",
    "))\n",
    "\n",
    "display(control_panel_layout)\n"
   ],
   "id": "5a1de2caa799e5b5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### 3. Data Loading and Validation\n",
    "This cell handles the critical first step of loading and validating the A/B test data. The code will read the specified Excel file, confirm its existence, and verify that it contains the necessary columns for the analysis: variant, reach, and conversion. This ensures the data is correctly structured before proceeding."
   ],
   "id": "1b54c2311f245adc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# --- 3. Data Loading and Validation ---\n",
    "# This cell loads the data you confirmed in the Control Panel into a pandas\n",
    "# DataFrame. It also validates that the file contains the required columns\n",
    "# ('variant', 'reach', 'conversion').\n",
    "\n",
    "# --- Define Expected Data Structure ---\n",
    "REQUIRED_COLUMNS = ['variant', 'reach', 'conversion']\n",
    "\n",
    "# --- Validation and Loading Logic ---\n",
    "# First, check if the 'uploaded_data_content' variable exists.\n",
    "# This variable is created only when you click \"Confirm Selections\" in the Control Panel.\n",
    "if 'uploaded_data_content' not in locals():\n",
    "    print(\"‚ùå Error: No data file has been confirmed yet.\")\n",
    "    print(\"   Please go back to the Control Panel, upload a file, and click 'Confirm Selections'.\")\n",
    "\n",
    "else:\n",
    "    # If the data exists, try to load and validate it.\n",
    "    try:\n",
    "        print(f\"Attempting to load data from '{confirmed_filename}'...\")\n",
    "\n",
    "        # Load the data from the in-memory variable into a pandas DataFrame.\n",
    "        # We use 'uploaded_data_content' instead of a file path.\n",
    "        df = pd.read_excel(uploaded_data_content)\n",
    "\n",
    "        # Check if all the required columns are in the DataFrame.\n",
    "        if all(col in df.columns for col in REQUIRED_COLUMNS):\n",
    "            # If validation is successful, print a confirmation and the data's head.\n",
    "            print(\"‚úÖ Success: File loaded and validated.\")\n",
    "            print(\"\\n--- First 5 Rows of the Dataset ---\")\n",
    "            print(df.head().to_string(index=False))\n",
    "        else:\n",
    "            # If columns are missing, identify them and report the error.\n",
    "            missing_cols = [col for col in REQUIRED_COLUMNS if col not in df.columns]\n",
    "            print(f\"---\")\n",
    "            print(f\"‚ùå Error: Missing Columns.\")\n",
    "            print(f\"The file '{confirmed_filename}' was loaded, but is missing required columns.\")\n",
    "            print(f\"   - Missing column(s): {missing_cols}\")\n",
    "            print(f\"   - Please ensure the file contains all of the following columns: {REQUIRED_COLUMNS}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        # Catch any other potential errors during the file reading process.\n",
    "        print(f\"---\")\n",
    "        print(f\"‚ùå An unexpected error occurred while reading the file: {e}\")\n"
   ],
   "id": "5f1361b781a403a8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### 4. Calculation of Posterior Parameters\n",
    "Here, we perform the core Bayesian update for our A/B test. üß™"
   ],
   "id": "abd7b472985bcbb7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# --- 4. Calculation of Posterior Parameters ---\n",
    "# This cell performs the core Bayesian update. It combines the prior belief\n",
    "# you selected in the Control Panel with the observed data (reach and conversions)\n",
    "# to calculate the posterior distribution for each variant.\n",
    "\n",
    "# First, check if the DataFrame 'df' exists from the previous step.\n",
    "if 'df' not in locals():\n",
    "    print(\"‚ùå Error: DataFrame 'df' not found.\")\n",
    "    print(\"   Please run the 'Data Loading and Validation' cell successfully before proceeding.\")\n",
    "else:\n",
    "    try:\n",
    "        # Get the selected prior values (alpha, beta) from the Control Panel widget\n",
    "        PRIOR_ALPHA, PRIOR_BETA = prior_selector.value\n",
    "\n",
    "        # --- Apply the Beta-Binomial Conjugate Update Rule ---\n",
    "        # posterior_alpha = prior_alpha + number_of_successes (conversions)\n",
    "        # posterior_beta = prior_beta + number_of_failures (reach - conversions)\n",
    "        df['posterior_alpha'] = PRIOR_ALPHA + df['conversion']\n",
    "        df['posterior_beta'] = PRIOR_BETA + (df['reach'] - df['conversion'])\n",
    "\n",
    "        # --- Display the Updated DataFrame ---\n",
    "        # Show the DataFrame with the newly calculated posterior parameters.\n",
    "        print(\"‚úÖ Success: Posterior parameters calculated.\")\n",
    "        print(\"\\n--- DataFrame with Updated Posterior Parameters ---\")\n",
    "        display_cols = ['variant', 'reach', 'conversion', 'posterior_alpha', 'posterior_beta']\n",
    "        print(df[display_cols].to_string(index=False))\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå An unexpected error occurred: {e}\")\n",
    "\n"
   ],
   "id": "34600db8b6eeee06",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### 5. Generation of the Posterior Plot\n",
    "\n",
    "This cell generates the most important visualization for our analysis: the posterior probability distributions. The ridgeline plot is used for better readability when comparing multiple variants."
   ],
   "id": "339d27af55852f67"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# --- 5. Generation of the Posterior Plot ---\n",
    "# This cell generates the most important visualization for our analysis: the\n",
    "# posterior probability distributions. The ridgeline plot is used for better\n",
    "# readability when comparing multiple variants.\n",
    "\n",
    "# First, check if the DataFrame 'df' with posterior parameters exists.\n",
    "if 'df' in locals() and 'posterior_alpha' in df.columns:\n",
    "    try:\n",
    "        # --- 1. Setup for Ridgeline Plot ---\n",
    "        # We sort by the posterior mean to have a more organized plot.\n",
    "        # The posterior mean is the average of the distribution.\n",
    "        if 'posterior_mean' not in df.columns:\n",
    "             df['posterior_mean'] = df['posterior_alpha'] / (df['posterior_alpha'] + df['posterior_beta'])\n",
    "\n",
    "        sorted_df = df.sort_values('posterior_mean', ascending=False)\n",
    "\n",
    "        # Create a figure and axes for the plot.\n",
    "        fig, ax = plt.subplots(figsize=(12, 2 + len(sorted_df) * 0.7))\n",
    "\n",
    "        # --- 1a. Create a color palette ---\n",
    "        # Use a colormap to get a unique color for each variant.\n",
    "        colors = plt.cm.viridis(np.linspace(0.1, 0.9, len(sorted_df)))\n",
    "\n",
    "        # --- 2. Dynamically Determine X-axis Range ---\n",
    "        # Ensure all distributions and their credible intervals are fully visible.\n",
    "        max_x = 0\n",
    "        for i, row in sorted_df.iterrows():\n",
    "            percentile_999 = stats.beta.ppf(0.999, row['posterior_alpha'], row['posterior_beta'])\n",
    "            if percentile_999 > max_x:\n",
    "                max_x = percentile_999\n",
    "        x = np.linspace(0, max_x * 1.05, 1000)\n",
    "\n",
    "        # --- 3. Plot Each Variant as a Ridge ---\n",
    "        y_offset_step = 0.8  # Controls vertical spacing between ridges\n",
    "\n",
    "        for i, (row, color) in enumerate(zip(sorted_df.itertuples(), colors)):\n",
    "            y_offset = i * y_offset_step\n",
    "\n",
    "            # Calculate the Probability Density Function (PDF)\n",
    "            pdf = stats.beta.pdf(x, row.posterior_alpha, row.posterior_beta)\n",
    "\n",
    "            # Plot the main distribution curve with a label for the legend.\n",
    "            ax.plot(x, pdf + y_offset, color=color, lw=1.5, label=row.variant)\n",
    "\n",
    "            # Add a light fill for the entire distribution\n",
    "            ax.fill_between(x, y_offset, pdf + y_offset, alpha=0.2, color=color)\n",
    "\n",
    "            # --- 4. Calculate and Shade the 95% Credible Interval ---\n",
    "            # This interval contains the true conversion rate with 95% probability.\n",
    "            ci_low, ci_high = stats.beta.ppf([0.025, 0.975], row.posterior_alpha, row.posterior_beta)\n",
    "\n",
    "            # Create a mask for the x-values within the credible interval\n",
    "            ci_mask = (x >= ci_low) & (x <= ci_high)\n",
    "\n",
    "            # Add a darker shade on top for the 95% credible interval\n",
    "            ax.fill_between(x[ci_mask], y_offset, pdf[ci_mask] + y_offset, alpha=0.4, color=color)\n",
    "\n",
    "        # --- 5. Finalize and Display the Plot ---\n",
    "        from matplotlib.patches import Patch\n",
    "\n",
    "        # Clean up the plot aesthetics\n",
    "        ax.set_title('Posterior Distributions of Conversion Rates', fontsize=16)\n",
    "        ax.set_xlabel('Conversion Rate', fontsize=12)\n",
    "        ax.set_yticks([]) # Hide y-axis ticks as they are not meaningful here\n",
    "        ax.spines['left'].set_visible(False)\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        ax.spines['top'].set_visible(False)\n",
    "\n",
    "        # Create and display a custom legend\n",
    "        handles, labels = ax.get_legend_handles_labels()\n",
    "\n",
    "        # Add \"Variant\" prefix to each label\n",
    "        new_labels = [f'Variant {label}' for label in labels]\n",
    "\n",
    "        # Create a proxy artist for the shaded area to include in the legend\n",
    "        ci_patch = Patch(color='gray', alpha=0.4, label='95% Credible Interval')\n",
    "        handles.append(ci_patch)\n",
    "        new_labels.append('95% Credible Interval')\n",
    "\n",
    "        # Position the legend above the plot in the top-right corner with a smaller font\n",
    "        fig.legend(handles, new_labels, title=\"Legend\", bbox_to_anchor=(0.98, 0.98), loc='upper right', fontsize='small')\n",
    "\n",
    "        plt.tight_layout(rect=[0, 0, 1, 0.95]) # Adjust layout to make space for the title and legend\n",
    "        plt.show()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå An unexpected error occurred while generating the plot: {e}\")\n",
    "else:\n",
    "    print(\"‚ùå Error: DataFrame 'df' with posterior parameters not found.\")\n",
    "    print(\"   Please run the previous cells successfully before proceeding.\")\n"
   ],
   "id": "daafde3df8f8301",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### 6. # Monte Carlo Simulation\n",
    "\n",
    "Run this cell to start the Monte Carlo Simulation and create 100.000 random samples."
   ],
   "id": "236e80b258b92449"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Monte Carlo Simulation\n",
    "\n",
    "# This cell performs a Monte Carlo simulation to draw random samples from the\n",
    "# posterior distribution of each variant. These samples will allow us to\n",
    "# empirically compare the variants and calculate key metrics, such as the\n",
    "# probability of one being better than the other and the expected loss.\n",
    "\n",
    "# --- 1. Simulation Setup ---\n",
    "# Define the number of random samples to generate for each variant's distribution.\n",
    "# A larger number of samples leads to more stable and accurate estimates of our metrics.\n",
    "N_SAMPLES = 100000\n",
    "\n",
    "# We will store the generated samples in a dictionary, with variant names as keys.\n",
    "posterior_samples = {}\n",
    "\n",
    "\n",
    "# --- 2. Run Simulation ---\n",
    "# Check if the dataframe 'df' with posterior parameters exists to avoid errors.\n",
    "if 'df' in locals() and 'posterior_alpha' in df.columns:\n",
    "\n",
    "    # Iterate over each variant (row) in the DataFrame.\n",
    "    for i, row in df.iterrows():\n",
    "        variant_name = row['variant']\n",
    "        p_alpha = row['posterior_alpha']\n",
    "        p_beta = row['posterior_beta']\n",
    "\n",
    "        # Generate N_SAMPLES from the Beta distribution defined by the variant's\n",
    "        # posterior parameters. Each sample represents a plausible \"true\"\n",
    "        # conversion rate for that variant, according to our model.\n",
    "        samples = stats.beta.rvs(a=p_alpha, b=p_beta, size=N_SAMPLES)\n",
    "\n",
    "        # Store the resulting array of samples in our dictionary.\n",
    "        posterior_samples[variant_name] = samples\n",
    "\n",
    "    # --- 3. Output: Simulation Summary ---\n",
    "    # The simulation is complete. The following is a summary of the process.\n",
    "    print(\"--- Monte Carlo Simulation Summary ---\")\n",
    "    print(f\"‚úÖ Simulation completed successfully.\")\n",
    "    print(f\"   - Samples generated per variant: {N_SAMPLES:,}\")\n",
    "    print(f\"   - Variants simulated: {list(posterior_samples.keys())}\")\n",
    "\n",
    "    print(\"\\nData Preview (first 3 samples for each variant):\")\n",
    "    for variant, samples in posterior_samples.items():\n",
    "        preview = [round(s, 6) for s in samples[:3]]\n",
    "        print(f\"  - {variant}: {preview}\")\n",
    "\n",
    "    print(\"\\nThe 'posterior_samples' dictionary is now ready for metric calculation in the next cell.\")\n",
    "\n",
    "else:\n",
    "    # This message will only be displayed if the prerequisite DataFrame is not found.\n",
    "    print(\"Error: DataFrame 'df' with posterior parameters not found.\")\n",
    "    print(\"Please ensure the data loading (Cell 5) and posterior calculation (Cell 7) were executed successfully.\")"
   ],
   "id": "fb15b530dd5c025d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### 6. Calculation and Presentation of Metrics\n",
    "This is the final calculation step where we translate our simulation results into actionable business metrics. üèÜ"
   ],
   "id": "667f4aa713eb94f4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# --- 7. Calculation and Presentation of Metrics ---\n",
    "# This cell translates our simulation results into actionable business metrics:\n",
    "# 1. Probability of Being Best: The likelihood that a variant is the true winner.\n",
    "# 2. Expected Loss (Risk): The cost of being wrong if you choose that variant.\n",
    "\n",
    "# First, check if the simulation data from the previous step exists.\n",
    "if 'posterior_samples' in locals():\n",
    "    try:\n",
    "        # --- Get the Risk Threshold from the Control Panel ---\n",
    "        # This line was missing. It retrieves the value set by the designer.\n",
    "        RISK_THRESHOLD = risk_slider.value\n",
    "\n",
    "        # --- 1. Combine Simulation Samples into a DataFrame ---\n",
    "        samples_df = pd.DataFrame(posterior_samples)\n",
    "        samples_df['max_conversion_rate'] = samples_df.max(axis=1)\n",
    "        variant_names = list(posterior_samples.keys())\n",
    "\n",
    "        # --- 2. Calculate 'Probability to be Best' and 'Expected Loss' ---\n",
    "        results = []\n",
    "        for variant in variant_names:\n",
    "            prob_best = (samples_df[variant] == samples_df['max_conversion_rate']).mean()\n",
    "            loss = samples_df['max_conversion_rate'] - samples_df[variant]\n",
    "            expected_loss = loss.mean()\n",
    "            results.append({\n",
    "                \"Variant\": variant,\n",
    "                \"Probability to be Best\": prob_best,\n",
    "                \"Expected Loss (Risk)\": expected_loss\n",
    "            })\n",
    "\n",
    "        # --- 3. Format and Display Results as a Table ---\n",
    "        results_df = pd.DataFrame(results)\n",
    "\n",
    "        # Create the 'Decision Guide' column based on the threshold\n",
    "        conditions = [\n",
    "            results_df['Expected Loss (Risk)'] > RISK_THRESHOLD,\n",
    "            results_df['Expected Loss (Risk)'] < RISK_THRESHOLD\n",
    "        ]\n",
    "        choices = ['Above Threshold', 'Below Threshold']\n",
    "        results_df['Decision Guide'] = np.select(conditions, choices, default='Equals Threshold')\n",
    "\n",
    "        # Add other necessary columns from the main 'df' for the final report\n",
    "        if 'df' in locals():\n",
    "            results_df = pd.merge(results_df, df[['variant', 'posterior_mean']], left_on='Variant', right_on='variant', how='left').drop('variant', axis=1)\n",
    "\n",
    "        # Sort the DataFrame by the lowest risk\n",
    "        results_df = results_df.sort_values(by=\"Expected Loss (Risk)\")\n",
    "\n",
    "        # --- 4. Final Styling ---\n",
    "        styled_df = results_df.style.format({\n",
    "            \"Probability to be Best\": \"{:.2%}\",\n",
    "            \"Expected Loss (Risk)\": \"{:.4%}\"\n",
    "        }).set_properties(**{'text-align': 'center'}) \\\n",
    "        .set_caption(f\"üèÜ Bayesian A/B Test Results (Risk Threshold: {RISK_THRESHOLD:.1%})\") \\\n",
    "        .hide(axis=\"index\")\n",
    "\n",
    "        # Display the final, styled table\n",
    "        display(styled_df)\n",
    "        print(\"\\n(A variant with risk 'Below Threshold' is generally considered a safe choice.)\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå An unexpected error occurred: {e}\")\n",
    "else:\n",
    "    print(\"‚ùå Error: The 'posterior_samples' dictionary was not found.\")\n",
    "    print(\"   Please ensure the Monte Carlo Simulation cell was executed successfully.\")\n"
   ],
   "id": "c4fd4446b762dcdb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### 7. Automated Conclusion Logic\n",
    "This final, automated cell translates our statistical results into a clear business recommendation with key metrics. üéØ"
   ],
   "id": "84061d34cea7335d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# --- 9. Automated Report & Recommendation ---\n",
    "# This final cell interprets the results and generates a clear, text-based\n",
    "# recommendation with detailed explanations of the key metrics, formatted in Markdown.\n",
    "\n",
    "from IPython.display import display, Markdown\n",
    "import pandas as pd\n",
    "\n",
    "# First, check if the results_df DataFrame from the previous step exists.\n",
    "if 'results_df' not in locals():\n",
    "    print(\"‚ùå Error: The 'results_df' DataFrame was not found.\")\n",
    "    print(\"   Please run the 'Calculation and Presentation of Metrics' cell successfully before proceeding.\")\n",
    "else:\n",
    "    try:\n",
    "        # --- Get Risk Threshold from Control Panel ---\n",
    "        RISK_THRESHOLD = risk_slider.value\n",
    "\n",
    "        # --- Ensure all necessary data is in results_df for the report ---\n",
    "        # This makes the cell robust by checking for and merging only the required columns\n",
    "        # that are actually missing from the original 'df' DataFrame.\n",
    "        if 'df' in locals():\n",
    "            required_cols = ['posterior_mean', 'reach', 'conversion']\n",
    "            missing_cols = [col for col in required_cols if col not in results_df.columns]\n",
    "\n",
    "            if missing_cols:\n",
    "                cols_to_merge = ['variant'] + missing_cols\n",
    "                # Ensure the original df has the columns before merging\n",
    "                if all(col in df.columns for col in cols_to_merge):\n",
    "                    results_df = pd.merge(results_df, df[cols_to_merge], left_on='Variant', right_on='variant', how='left')\n",
    "                    if 'variant' in results_df.columns:\n",
    "                         results_df = results_df.drop('variant', axis=1)\n",
    "\n",
    "        # --- Extract Key Information ---\n",
    "        best_candidate = results_df.iloc[0]\n",
    "\n",
    "        is_winner = best_candidate['Expected Loss (Risk)'] < RISK_THRESHOLD\n",
    "\n",
    "        # --- Build the Markdown Report String in the new order ---\n",
    "        markdown_report = \"\"\n",
    "\n",
    "        # 1. Add the Verdict (Order: 1st)\n",
    "        if is_winner:\n",
    "            markdown_report += f\"## ‚úÖ Verdict: Test Concluded. Deploy Variant '{best_candidate['Variant']}'.\\n\"\n",
    "        else:\n",
    "            markdown_report += f\"## ‚ö†Ô∏è Verdict: Test Inconclusive. Collect More Data.\\n\"\n",
    "\n",
    "        markdown_report += \"---\\n\"\n",
    "\n",
    "        # 2. Add the Stakeholder Summary (Order: 2nd)\n",
    "        markdown_report += \"### Summary for Stakeholders\\n\"\n",
    "\n",
    "        if is_winner:\n",
    "            summary_text = f\"The analysis confidently recommends deploying **Variant '{best_candidate['Variant']}'**. It has the highest chance of being the best option, and the risk of choosing it is well below our safety limit of {RISK_THRESHOLD:.1%}. The table in the final section shows the expected performance increase against all other variants.\"\n",
    "        else:\n",
    "            summary_text = f\"The results are not yet clear enough to make a confident decision. Our best option still has a risk level higher than our limit. We recommend collecting more data to get a clearer winner.\"\n",
    "\n",
    "        markdown_report += summary_text + \"\\n\\n---\\n\"\n",
    "\n",
    "        # 3. Add Key Metrics Explained (Order: 3rd)\n",
    "        markdown_report += \"### Key Metrics Explained\\n\"\n",
    "\n",
    "        prob_best_str = f\"{best_candidate['Probability to be Best']:.1%}\"\n",
    "        markdown_report += f\"**üîπ Probability to be Best: {prob_best_str}**\\n\"\n",
    "        markdown_report += f\"   - *What it means:* This is the probability that Variant '{best_candidate['Variant']}' is truly the best option among all variants tested. A higher percentage means more confidence in it being the winner.\\n\\n\"\n",
    "\n",
    "        risk_str = f\"{best_candidate['Expected Loss (Risk)']:.4%}\"\n",
    "        markdown_report += f\"**üîπ Risk (Expected Loss): {risk_str}**\\n\"\n",
    "        markdown_report += f\"   - *What it means:* This is the 'cost of being wrong.' It represents the average potential drop in conversion rate you would risk by choosing this variant if another one was secretly better. A lower risk is better.\\n\\n\"\n",
    "\n",
    "        markdown_report += f\"**üîπ Expected Uplift**\\n\"\n",
    "        markdown_report += f\"   - *What it means:* This is the expected percentage increase in the conversion rate of the winning variant compared to another. The table below shows this uplift and the **potential gain in conversions** for the same number of visitors.\\n\"\n",
    "\n",
    "        # 4. Add the Expected Uplift Table (Order: 4th, only if there's a winner)\n",
    "        required_cols_for_table = ['posterior_mean', 'reach', 'conversion']\n",
    "        if is_winner and len(results_df) > 1 and all(col in results_df.columns for col in required_cols_for_table):\n",
    "            markdown_report += \"\\n---\\n\"\n",
    "            markdown_report += \"### Expected Uplift vs. Other Variants\\n\"\n",
    "            markdown_report += \"| Compared To | Expected Uplift | Potential Conversion Gain | Total Expected Conversions |\\n\"\n",
    "            markdown_report += \"|:---|:---|:---|:---|\\n\"\n",
    "\n",
    "            # Add the winner's own data as the first row for reference\n",
    "            winner_conversions = best_candidate['conversion']\n",
    "            markdown_report += f\"| **Variant '{best_candidate['Variant']}' (Winner)** | **-** | **{int(winner_conversions)} conversions (actual)** | **{int(winner_conversions)}** |\\n\"\n",
    "\n",
    "            # Loop through all other variants to create the comparison rows\n",
    "            for i, other_variant in results_df.iloc[1:].iterrows():\n",
    "                uplift = (best_candidate['posterior_mean'] - other_variant['posterior_mean']) / other_variant['posterior_mean']\n",
    "                # Corrected Calculation: This shows the *additional* conversions the winner\n",
    "                # is expected to get compared to the other variant, given the same number of visitors.\n",
    "                conversion_gain = (best_candidate['posterior_mean'] - other_variant['posterior_mean']) * best_candidate['reach']\n",
    "                total_expected = winner_conversions + conversion_gain\n",
    "                markdown_report += f\"| Variant '{other_variant['Variant']}' | +{uplift:.2%} | **+{int(round(conversion_gain, 0))}** more conversions | {int(round(total_expected, 0))} |\\n\"\n",
    "            markdown_report += \"\\n\"\n",
    "\n",
    "        # --- Display the final Markdown report ---\n",
    "        display(Markdown(markdown_report))\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå An unexpected error occurred while generating the report: {e}\")\n"
   ],
   "id": "62365a9c7c89e4db",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
